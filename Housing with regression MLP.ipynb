{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vocational-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unlike-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full ,y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train ,y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bottom-somalia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1824 - val_loss: 0.5313\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 570us/step - loss: 0.5289 - val_loss: 0.4888\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 560us/step - loss: 0.4972 - val_loss: 0.5015\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 545us/step - loss: 0.6311 - val_loss: 0.4976\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 537us/step - loss: 0.4895 - val_loss: 0.4646\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 602us/step - loss: 0.5167 - val_loss: 0.4502\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 602us/step - loss: 0.4371 - val_loss: 0.4574\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 549us/step - loss: 0.4551 - val_loss: 0.4263\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.4131 - val_loss: 0.4299\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 556us/step - loss: 0.4711 - val_loss: 0.4266\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 549us/step - loss: 0.4421 - val_loss: 0.4140\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.4052 - val_loss: 0.4088\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.4418 - val_loss: 0.4027\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 552us/step - loss: 0.4207 - val_loss: 0.4031\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 540us/step - loss: 0.4099 - val_loss: 0.4029\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 544us/step - loss: 0.4421 - val_loss: 0.3995\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 560us/step - loss: 0.4369 - val_loss: 0.3994\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 542us/step - loss: 0.4070 - val_loss: 0.3902\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 551us/step - loss: 0.3887 - val_loss: 0.3900\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.3873 - val_loss: 0.3889\n",
      "162/162 [==============================] - 0s 339us/step - loss: 0.4020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.7518575],\n",
       "       [0.8805359],\n",
       "       [3.1173038]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                   validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nuclear-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build more complex models WiedDeep https://homl.info/widedeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "disciplinary-duplicate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 796us/step - loss: 1.8122 - val_loss: 1.9626\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 584us/step - loss: 1.2357 - val_loss: 28.2800\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 607us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 590us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 592us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 585us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 566us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 588us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 570us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 666us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 630us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 589us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 569us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 591us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 581us/step - loss: nan - val_loss: nan\n",
      "162/162 [==============================] - 0s 351us/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                   validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "together-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_A)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vanilla-prime",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 831us/step - loss: 3.0821 - val_loss: 0.7733\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 619us/step - loss: 0.7816 - val_loss: 0.7125\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 620us/step - loss: 0.7259 - val_loss: 0.6809\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 629us/step - loss: 0.6781 - val_loss: 0.6592\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 628us/step - loss: 0.6418 - val_loss: 0.6427\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 616us/step - loss: 0.6676 - val_loss: 0.6298\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 616us/step - loss: 0.6400 - val_loss: 0.6164\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 621us/step - loss: 0.6220 - val_loss: 0.6074\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 622us/step - loss: 0.6085 - val_loss: 0.6014\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 619us/step - loss: 0.5981 - val_loss: 0.5951\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 621us/step - loss: 0.5983 - val_loss: 0.5885\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 623us/step - loss: 0.6150 - val_loss: 0.5845\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 628us/step - loss: 0.6014 - val_loss: 0.5801\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 628us/step - loss: 0.6251 - val_loss: 0.5760\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 628us/step - loss: 0.5900 - val_loss: 0.5712\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 636us/step - loss: 0.5740 - val_loss: 0.5680\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 623us/step - loss: 0.5726 - val_loss: 0.5649\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 627us/step - loss: 0.5837 - val_loss: 0.5625\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 630us/step - loss: 0.5827 - val_loss: 0.5595\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 625us/step - loss: 0.5650 - val_loss: 0.5570\n",
      "162/162 [==============================] - 0s 385us/step - loss: 0.5812\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                   validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "attended-oasis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5196872],\n",
       "       [0.941691 ],\n",
       "       [3.0656495]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "published-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes we might need to have multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "strange-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_A)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suburban-analyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.5384 - output_loss: 1.3702 - aux_output_loss: 3.0526 - val_loss: 0.6495 - val_output_loss: 0.6413 - val_aux_output_loss: 0.7228\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 801us/step - loss: 0.6356 - output_loss: 0.6268 - aux_output_loss: 0.7148 - val_loss: 0.5984 - val_output_loss: 0.5942 - val_aux_output_loss: 0.6365\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 808us/step - loss: 0.5840 - output_loss: 0.5794 - aux_output_loss: 0.6254 - val_loss: 0.5737 - val_output_loss: 0.5698 - val_aux_output_loss: 0.6081\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 791us/step - loss: 0.6090 - output_loss: 0.6063 - aux_output_loss: 0.6341 - val_loss: 0.5641 - val_output_loss: 0.5608 - val_aux_output_loss: 0.5930\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 787us/step - loss: 0.7030 - output_loss: 0.7162 - aux_output_loss: 0.5838 - val_loss: 0.5577 - val_output_loss: 0.5551 - val_aux_output_loss: 0.5803\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 787us/step - loss: 0.5607 - output_loss: 0.5573 - aux_output_loss: 0.5913 - val_loss: 0.5782 - val_output_loss: 0.5789 - val_aux_output_loss: 0.5719\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 787us/step - loss: 0.5630 - output_loss: 0.5610 - aux_output_loss: 0.5805 - val_loss: 0.5299 - val_output_loss: 0.5267 - val_aux_output_loss: 0.5579\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 793us/step - loss: 0.5356 - output_loss: 0.5334 - aux_output_loss: 0.5556 - val_loss: 0.5268 - val_output_loss: 0.5235 - val_aux_output_loss: 0.5560\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 817us/step - loss: 0.5278 - output_loss: 0.5243 - aux_output_loss: 0.5589 - val_loss: 0.5138 - val_output_loss: 0.5104 - val_aux_output_loss: 0.5441\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 793us/step - loss: 0.5213 - output_loss: 0.5182 - aux_output_loss: 0.5491 - val_loss: 0.5106 - val_output_loss: 0.5073 - val_aux_output_loss: 0.5398\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 787us/step - loss: 0.5189 - output_loss: 0.5157 - aux_output_loss: 0.5468 - val_loss: 0.5063 - val_output_loss: 0.5035 - val_aux_output_loss: 0.5316\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 825us/step - loss: 0.5143 - output_loss: 0.5111 - aux_output_loss: 0.5428 - val_loss: 0.5063 - val_output_loss: 0.5038 - val_aux_output_loss: 0.5289\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 792us/step - loss: 0.5033 - output_loss: 0.5005 - aux_output_loss: 0.5285 - val_loss: 0.5034 - val_output_loss: 0.5010 - val_aux_output_loss: 0.5258\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 890us/step - loss: 0.5084 - output_loss: 0.5055 - aux_output_loss: 0.5340 - val_loss: 0.5125 - val_output_loss: 0.5108 - val_aux_output_loss: 0.5279\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 835us/step - loss: 0.5115 - output_loss: 0.5087 - aux_output_loss: 0.5372 - val_loss: 0.4970 - val_output_loss: 0.4946 - val_aux_output_loss: 0.5187\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 847us/step - loss: 0.4932 - output_loss: 0.4910 - aux_output_loss: 0.5126 - val_loss: 0.4987 - val_output_loss: 0.4968 - val_aux_output_loss: 0.5157\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.5115 - output_loss: 0.5095 - aux_output_loss: 0.5292 - val_loss: 0.5040 - val_output_loss: 0.5024 - val_aux_output_loss: 0.5179\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 789us/step - loss: 0.5132 - output_loss: 0.5110 - aux_output_loss: 0.5334 - val_loss: 0.4948 - val_output_loss: 0.4927 - val_aux_output_loss: 0.5131\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 817us/step - loss: 0.5137 - output_loss: 0.5115 - aux_output_loss: 0.5335 - val_loss: 0.4976 - val_output_loss: 0.4961 - val_aux_output_loss: 0.5109\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 805us/step - loss: 0.4946 - output_loss: 0.4925 - aux_output_loss: 0.5139 - val_loss: 0.5057 - val_output_loss: 0.5052 - val_aux_output_loss: 0.5105\n",
      "162/162 [==============================] - 0s 564us/step - loss: 0.5102 - output_loss: 0.5089 - aux_output_loss: 0.5219\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), [y_train, y_train], epochs=20,\n",
    "                   validation_data=((X_valid_A, X_valid_B), [y_valid, y_valid]))\n",
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "regional-rating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2.652348  ],\n",
       "        [0.94603634],\n",
       "        [3.3610392 ]], dtype=float32),\n",
       " array([[2.7169838],\n",
       "        [0.956499 ],\n",
       "        [3.26734  ]], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-library",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
